---
title: "Algoritmos de machine learning para la predicción de actividad en organos judiciales"
author: "Claudio Sebastián Castillo"
date: "3/8/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# biblio
# https://otexts.com/fpp2/ 
# https://cran.r-project.org/web/packages/modeltime/vignettes/getting-started-with-modeltime.html (excelente!)
# https://medium.com/towards-data-science/multiple-time-series-forecast-demand-pattern-classification-using-r-part-1-31601158d33b
# https://arxiv.org/ftp/arxiv/papers/2203/2203.06848.pdf
# https://jisajournal.springeropen.com/track/pdf/10.1186/s13174-021-00137-8.pdf
# https://towardsdatascience.com/multiple-time-series-forecast-demand-pattern-classification-using-r-part-1-31601158d33b
# https://www.cienciadedatos.net/documentos/py39-forecasting-series-temporales-con-skforecast-xgboost-lightgbm-catboost.html
# https://towardsdatascience.com/multi-step-time-series-forecasting-with-arima-lightgbm-and-prophet-cc9e3f95dfb0
# https://towardsdatascience.com/lazyprophet-time-series-forecasting-with-lightgbm-3745bafe5ce5
#   https://github.com/tblume1992/LazyProphet
# https://www.kaggle.com/code/rohanrao/a-modern-time-series-tutorial/notebook
# https://www.kaggle.com/code/ashishpatel26/light-gbm-demand-forecasting/notebook
# predict with R
# https://www.kaggle.com/code/kailex/m5-forecaster-v2

pacman::p_load(tidyverse, magrittr) # data wrangling packages
# pacman::p_load(lubridate, tsintermittent, fpp3, modeltime, timetk, modeltime.gluonts, tidymodels, modeltime.ensemble, modeltime.resample) # time series model packages
pacman::p_load(foreach, future) # parallel functions
pacman::p_load(viridis, plotly) # visualizations packages
theme_set(hrbrthemes::theme_ipsum()) # set default themes

source("main.R")

# This toggles plots from plotly (interactive) to ggplot (static)
interactive <- FALSE

```

# Introducción

La actividad de un órgano judicial está vinculada al volumen de causas o procesos radicados en él. Este volumen de causas o procesos implica, en la práctica, un volumen aún mayor de transacciones asociadas a las peticiones que realizan las partes y las respuestas generadas por el órgano en el marco de cada proceso. De esta manera el servicio que presta cada órgano judicial a un ciudadano se traduce -generalmente- en una interacción entre peticiones y respuestas, desde el inicio de un proceso con la presentación de una demanda hasta la conclusión del mismo con el dictado de una sentencia.     

Desde esa perspectiva, un buen servicio de justicia podría verse como aquél que ante cada petición de un ciudadano es capaz de responder rápidamente y cumpliendo con los criterios de justicia que deben aplicarse al caso según la ley. Incluso podría decirse que la primera parte de esa definición es redundante pues la rapidez en la respuesta, o mejor dicho, 'el cumplimiento de plazos' al ser un requisito legal es también uno de los 'criterios de justicia' que debe satisfacer todo órgano judicial. Esta idea se ha plasmado dentro el mundo judicial en frases como 'la justicia lenta no es justicia' (Dra.Hilda Kogan,vocal de la Suprema Corte de la Provincia de Buenos Aires, accesible [aquí](https://magistradoslp.org.ar/project/dra-hilda-kogan-la-justicia-lenta-no-es-justicia/).   

En esa línea, puede verse con claridad que administrar eficientemente las peticiones que recibe un órgano judicial es una parte vital del servicio de justicia. Precisamente en este punto aparece la necesidad de contar no solo con estrategias de control de las peticiones ingresadas sino también de previsión de las peticiones futuras. Surge así el problema de elaborar 'pronósticos sobre la demanda' que no sería otra cosa que elaborar una idea aproximada de las peticiones que ingresarán a un órgano judicial en un período determinado. Dicho pronóstico no solo permitiría preveer los recursos necesarios para afrontar la carga de actividad que tendrá un ógano, sino también -y acaso más importante aún- poder evaluar escenarios generales y detectar cambios estructurales en la demanda que requieren otro tipo de abordajes.  


# Trabajos vinculados (antecedentes)

Elaborar pronósticos y proyecciones sobre variables importantes de un negocio es algo común en el mundo privado, aunque no abundan los casos documentados en el ambito público judicial. La abundante bibliografía que existe en materia de planificación y gestión judicial contrasta con la relativamente escasa producción relativa a estrategias de proyección de indicadores vinculados al servicio de justicia. 

Por otro lado, contamos con abundante material que aborda el tema de generar proyecciones o prónosticos sobre variables importantes para un negocio a partir de modelos estadísticos y modelos de *machine learning*. 
<!-- Importante revisión métodos "Review of ML and AutoML Solutions to Forecast Time‑Series Data" -->



```{r}
# aplicado a justicia 
# Desarrollar
# - https://ncsc.contentdm.oclc.org/digital/collection/ctadmin/id/2158/
# - https://www.ncsc.org/__data/assets/pdf_file/0019/19234/role-of-strategic-planning-and-strategic-management-in-the-courts.pdf

# forecast
# https://link.springer.com/content/pdf/10.1007/s11831-022-09765-0.pdf


```

# Explorando el problema y los datos


```{r}
skimr::skim(df)

```

## Presentaciones por día

```{r}
df_presentanciones = df %>% 
  group_by(fecha) %>% 
  summarise(presentaciones_abogados = sum(presentaciones_abogados, na.rm = T)) 

df_presentanciones_xmes = df_presentanciones %>% 
  mutate(fecha = lubridate::floor_date(fecha, unit = "month")) %>%
  group_by(fecha) %>% summarise(presentaciones_abogados = sum(presentaciones_abogados, na.rm = T)) %>% 
  na.omit() 
  
df_presentanciones_xmes %>%   
  plot_time_series(fecha, presentaciones_abogados, 
                   .title = "Presentaciones digitales de abogados en el Poder Judicial de Entre Rios por mes", 
                   .x_lab = "mes", 
                   .y_lab = "presentaciones_digitales")

```

## Presentaciones por Circunscripcion

```{r}
df %>% 
  group_by(circunscripcion, fecha) %>% 
  summarise(presentaciones_abogados = sum(presentaciones_abogados, na.rm = T)) %>% 
  ggplot()+
  geom_density(aes(x = presentaciones_abogados, fill = as_factor(circunscripcion)), alpha = 0.5)+
  scale_x_log10()+
  theme(legend.position = "note") +
  labs(title = "Presentaciones por Circunscripcion ", 
       subtitle = "", fill = "Circunscripcion", x = "Presentaciones Diarias") + 
  facet_wrap( ~ circunscripcion, scales = "free")
  
```

## Presentaciones por Mes

```{r}
options(scipen = 999)

df %>% 
  mutate(mes = lubridate::month(fecha, label = T)) %>% ungroup() %>% 
  group_by(mes) %>% 
  summarise_if(is.numeric, sum, na.rm = TRUE) %>% ungroup() %>% 
  pivot_longer(!mes, names_to = "evento", values_to = "cantidad") %>% 
  mutate(evento = factor(evento, levels = c("causas_iniciadas", 
                                            "presentaciones_abogados",
                                            "actos_procesales"), ordered = T)) %>% 
  ggplot()+
    geom_col(aes(x = mes, y = cantidad, fill=mes))+
    scale_fill_viridis_d()+
    labs(title = "Causas Iniciadas, presentaciones digitales y actos procesales por mes del año", 
         x = 'mes',
         y = 'cantidad',
         fill = 'mes') +
     facet_wrap( ~ evento)
```
## Presentaciones por día de Semana

```{r}
options(scipen = 999)

df %>% 
  mutate(diaS = lubridate::wday(fecha, label = T)) %>% ungroup() %>% 
  group_by(diaS) %>% 
  summarise_if(is.numeric, sum, na.rm = TRUE) %>% ungroup() %>% 
  pivot_longer(!diaS, names_to = "evento", values_to = "cantidad") %>% 
  mutate(evento = factor(evento, levels = c("causas_iniciadas", 
                                            "presentaciones_abogados",
                                            "actos_procesales"), ordered = T)) %>% 
  ggplot()+
    geom_col(aes(x = diaS, y = cantidad, fill=diaS))+
    scale_fill_viridis_d()+
    labs(title = "Causas Iniciadas, presentaciones digitales y actos procesales por día de semana", 
         x = 'día se semana',
         y = 'cantidad',
         fill = 'día de la semana') +
     facet_wrap( ~ evento)
```
## Correlación

```{r}
GGally::ggpairs(df %>% select_if(is.numeric))

```

# Modelos predictivos para serie temporal de presentaciones sin variables predictoras

Siguiendo a : # https://cran.r-project.org/web/packages/modeltime/vignettes/getting-started-with-modeltime.html

## Dividimos el data set para entrenamiento de modelos

```{r}

df_presentanciones_xmes = df_presentanciones_xmes %>% rename(date = fecha, value = presentaciones_abogados)
splits <- initial_time_split(df_presentanciones_xmes, prop = 0.8)
```

## Creando modelos: ARIMA, Exponential Smoothing, Linear Regression y MARS


### 1 Auto ARIMA 

```{r}

model_fit_arima_no_boost <- arima_reg() %>%
    set_engine(engine = "auto_arima") %>%
    fit(value ~ date, data = training(splits))


```
### 2: Boosted Auto ARIMA 

```{r}
model_fit_arima_boosted <- arima_boost(min_n = 2, learn_rate = 0.015) %>%
    set_engine(engine = "auto_arima_xgboost") %>%
    fit(value ~ date + as.numeric(date) + factor(month(date, label = TRUE), ordered = F),
        data = training(splits))
```
### 3 Exponential Smoothing 

```{r}
model_fit_ets <- exp_smoothing() %>%
    set_engine(engine = "ets") %>%
    fit(value ~ date, data = training(splits))
```
### 4 Prophet 

```{r}
model_fit_prophet <- prophet_reg() %>%
    set_engine(engine = "prophet") %>%
    fit(value ~ date, data = training(splits))

```
### 5 Linear Regression 

```{r}
model_fit_lm <- linear_reg() %>%
    set_engine("lm") %>%
    fit(value ~ as.numeric(date) + factor(month(date, label = TRUE), ordered = FALSE),
        data = training(splits))
```

### 6 MARS

```{r}
model_spec_mars <- mars(mode = "regression") %>%
    set_engine("earth") 

recipe_spec <- recipe(value ~ date, data = training(splits)) %>%
    step_date(date, features = "month", ordinal = FALSE) %>%
    step_mutate(date_num = as.numeric(date)) %>%
    step_normalize(date_num) %>%
    step_rm(date)
  
wflw_fit_mars <- workflow() %>%
    add_recipe(recipe_spec) %>%
    add_model(model_spec_mars) %>%
    fit(training(splits))
```

## Entrenando los modelos creados

Note that some of the models have tunable parameters. It’s expected that tuning and parameter selection is performed prior to incorporating into a Modeltime Table.   


```{r}
models_tbl <- modeltime_table(
    model_fit_arima_no_boost,
    model_fit_arima_boosted,
    model_fit_ets,
    model_fit_prophet,
    model_fit_lm,
    wflw_fit_mars
)
```


## Calibrando los modelos

Calibrating adds a new column, .calibration_data, with the test predictions and residuals inside. A few notes on Calibration:
Calibration is how confidence intervals and accuracy metrics are determined
Calibration Data is simply forecasting predictions and residuals that are calculated from out-of-sample data.
After calibrating, the calibration data follows the data through the forecasting workflow.

```{r}
calibration_tbl <- models_tbl %>%
    modeltime_calibrate(new_data = testing(splits))
```

## Evaluando predicciones en datos de Testing y comprobando la precisión de los modelos



```{r}
calibration_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = df_presentanciones_xmes
    ) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = interactive
    )
```

```{r}
calibration_tbl %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy(
        .interactive = interactive)
```

From the accuracy metrics:
Model 5: LM is clearly the winner here with MAE of 8833


## Refit to Full Dataset & Forecast Forward

```{r}
refit_tbl <- calibration_tbl %>%
    modeltime_refit(data = df_presentanciones_xmes)

refit_tbl %>%
    modeltime_forecast(h = "1 years", actual_data = df_presentanciones_xmes) %>%
    plot_modeltime_forecast(
      .legend_max_width = 25, # For mobile screens
      .interactive      = interactive)

```

# LightGBM

Optimizacion Bayesiana. Próximamente implementar [new_stoping_criterion](https://www.amazon.science/publications/automatic-termination-for-hyperparameter-optimization)


# Resultados

